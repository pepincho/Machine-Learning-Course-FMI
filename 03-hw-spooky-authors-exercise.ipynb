{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spooky Author Identification exercise\n",
    "\n",
    "Spooky authors dataset. Mоже да се изтегли от тук:\n",
    "https://www.kaggle.com/c/spooky-author-identification\n",
    "\n",
    "#### Изводи\n",
    "\n",
    "След направените анализи в/у feature-те по време на лекцията на курса можем да стигнем до следните наблюдения и изводи:\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "Също така можем да опитаме някакъв feature engineering, \"почиставне\" и обработка на данните:\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "### Стратегия\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Започваме\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages\n",
      "Collecting mglearn\n",
      "  Downloading mglearn-0.1.6.tar.gz (541kB)\n",
      "\u001b[K    100% |████████████████████████████████| 542kB 944kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython)\n",
      "Requirement already satisfied: olefile in /opt/conda/lib/python3.6/site-packages (from pillow)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from traitlets>=4.2->ipython)\n",
      "Building wheels for collected packages: mglearn\n",
      "  Running setup.py bdist_wheel for mglearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/79/8b/2b/17dcfb9c9b044b216a58daea9787a0637cb1ffc5b4c2a78e50\n",
      "Successfully built mglearn\n",
      "Installing collected packages: mglearn\n",
      "Successfully installed mglearn-0.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy matplotlib ipython scikit-learn pandas pillow mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mglearn\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 2) (8392, 1) (8392, 3)\n",
      "{'author'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"data/spooky-authors/train.zip\", index_col=['id'])\n",
    "test = pd.read_csv(\"data/spooky-authors/test.zip\", index_col=['id'])\n",
    "sample_submission = pd.read_csv(\"data/spooky-authors/sample_submission.zip\", index_col=['id'])\n",
    "\n",
    "print(train.shape, test.shape, sample_submission.shape)\n",
    "print(set(train.columns) - set(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 558kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/18/9c/1f/276bc3f421614062468cb1c9d695e6086d0c73d67ea363c501\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"features__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "                      \"features__analyzer\": ['word'],\n",
    "                      \"features__max_df\": [1.0, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "                      \"features__min_df\": [2, 3, 5, 10],\n",
    "                      \"features__lowercase\": [False, True],\n",
    "                      \"features__stop_words\": [None, stopwords],\n",
    "                      \"features__token_pattern\": [r'\\w+|\\,', None],\n",
    "                      \"clf__alpha\": [0.01, 0.1, 0.5, 1, 2]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# stopset = set(stopwords.words('english'))\n",
    "\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(\n",
    "#         ngram_range=(1,2), min_df=2, \n",
    "#                                 max_df=0.8, lowercase=False, \n",
    "#                                 token_pattern=r'\\w+|\\,', stop_words=stopset\n",
    "                                )),\n",
    "    ('clf', MultinomialNB(\n",
    "#         alpha=0.01\n",
    "    )),\n",
    "])\n",
    "\n",
    "# print(pipeline.named_steps['features'])\n",
    "\n",
    "# print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3))\n",
    "# print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3, \n",
    "#                       scoring='neg_log_loss'))\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=4)\n",
    "\n",
    "random_search.fit(train.text, train.author)\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(train.text, train.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.98283890e-02   3.81339586e-03   9.76358215e-01]\n",
      " [  9.96057571e-01   3.11816161e-03   8.24267151e-04]\n",
      " [  7.44699788e-03   9.90084289e-01   2.46871320e-03]\n",
      " [  8.24766674e-01   1.73950931e-01   1.28239521e-03]\n",
      " [  5.33013756e-01   3.65558628e-01   1.01427616e-01]\n",
      " [  9.14797902e-01   8.29368343e-02   2.26526379e-03]\n",
      " [  8.60877068e-01   1.35091168e-01   4.03176395e-03]\n",
      " [  1.20976104e-02   1.99588590e-01   7.88313799e-01]\n",
      " [  9.92430401e-01   7.55044856e-03   1.91502121e-05]\n",
      " [  7.66137344e-01   9.48152515e-02   1.39047405e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.predict_proba(test[:10].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pipeline.predict_proba(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EAP' 'HPL' 'MWS']\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>MWS</th>\n",
       "      <th>HPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.976358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.996058</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.000824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.990084</td>\n",
       "      <td>0.002469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.824767</td>\n",
       "      <td>0.173951</td>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.533014</td>\n",
       "      <td>0.365559</td>\n",
       "      <td>0.101428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27337</th>\n",
       "      <td>0.914798</td>\n",
       "      <td>0.082937</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24265</th>\n",
       "      <td>0.860877</td>\n",
       "      <td>0.135091</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25917</th>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.199589</td>\n",
       "      <td>0.788314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04951</th>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14549</th>\n",
       "      <td>0.766137</td>\n",
       "      <td>0.094815</td>\n",
       "      <td>0.139047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       MWS       HPL\n",
       "id                                   \n",
       "id02310  0.019828  0.003813  0.976358\n",
       "id24541  0.996058  0.003118  0.000824\n",
       "id00134  0.007447  0.990084  0.002469\n",
       "id27757  0.824767  0.173951  0.001282\n",
       "id04081  0.533014  0.365559  0.101428\n",
       "id27337  0.914798  0.082937  0.002265\n",
       "id24265  0.860877  0.135091  0.004032\n",
       "id25917  0.012098  0.199589  0.788314\n",
       "id04951  0.992430  0.007550  0.000019\n",
       "id14549  0.766137  0.094815  0.139047"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file = pd.DataFrame(test_predictions, columns=['EAP', 'MWS', 'HPL'], index=test.index)\n",
    "submit_file.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file.to_csv(\"data/spooky-authors/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
